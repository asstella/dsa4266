{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped constant columns: ['icmp.unused', 'http.tls_port', 'udp.port', 'udp.stream', 'udp.time_delta', 'dns.qry.name', 'dns.qry.name.len', 'dns.qry.qu', 'dns.qry.type', 'dns.retransmission', 'dns.retransmit_request', 'dns.retransmit_request_in', 'mqtt.msg_decoded_as', 'mbtcp.len', 'mbtcp.trans_id', 'mbtcp.unit_id']\n",
      "Dropped high correlation columns: ['tcp.payload']\n",
      "Dropped low information columns: ['arp.dst.proto_ipv4', 'arp.src.proto_ipv4', 'mqtt.conack.flags', 'mqtt.conflag.cleansess', 'mqtt.conflags', 'mqtt.hdrflags', 'mqtt.len', 'mqtt.msg', 'mqtt.msgtype', 'mqtt.proto_len', 'mqtt.protoname', 'mqtt.topic', 'mqtt.topic_len', 'mqtt.ver']\n",
      "Dropped inconsistent columns: ['http.referer', 'http.request.full_uri', 'icmp.transmit_timestamp']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_17124\\1380327537.py:89: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Attack_type'] = df['Attack_type'].replace(type_mapping)\n"
     ]
    }
   ],
   "source": [
    "#################################################################################\n",
    "# Read in Data\n",
    "df = pd.read_pickle('final_df.pkl')\n",
    "\n",
    "#################################################################################\n",
    "# Convert all 0.0 to 0 for all columns\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    df[column] = df[column].replace({'0.0': '0', '0': '0'})\n",
    "\n",
    "#################################################################################\n",
    "# Drop constant columns\n",
    "constant_columns = [col for col in df.columns if df[col].nunique() == 1]\n",
    "df.drop(columns=constant_columns, inplace=True)\n",
    "print(f\"Dropped constant columns: {constant_columns}\")\n",
    "\n",
    "#################################################################################\n",
    "# Drop high correlation columns\n",
    "high_corr_columns = ['tcp.payload']\n",
    "df.drop(columns=high_corr_columns, inplace=True)\n",
    "print(f\"Dropped high correlation columns: {high_corr_columns}\")\n",
    "\n",
    "#################################################################################\n",
    "### Drop Low information column \n",
    "low_info_columns = ['arp.dst.proto_ipv4',\n",
    "                    'arp.src.proto_ipv4',\n",
    "                    'mqtt.conack.flags',\n",
    "                    'mqtt.conflag.cleansess',\n",
    "                    'mqtt.conflags', \n",
    "                    'mqtt.hdrflags',\n",
    "                    'mqtt.len',\n",
    "                    'mqtt.msg',\n",
    "                    'mqtt.msgtype',\n",
    "                    'mqtt.proto_len',\n",
    "                    'mqtt.protoname', \n",
    "                    'mqtt.topic',\n",
    "                    'mqtt.topic_len',\n",
    "                    'mqtt.ver']\n",
    "df.drop(columns=low_info_columns, inplace=True)\n",
    "print(f\"Dropped low information columns: {low_info_columns}\")\n",
    "#################################################################################\n",
    "# Drop Inconsistent Data columns\n",
    "inconsistent_columns = ['http.referer',\n",
    "                        'http.request.full_uri',\n",
    "                        'icmp.transmit_timestamp']\n",
    "\n",
    "df.drop(columns=inconsistent_columns, inplace=True)\n",
    "print(f\"Dropped inconsistent columns: {inconsistent_columns}\")\n",
    "#################################################################################\n",
    "# Drop Outliers\n",
    "df = df[df['tcp.seq'] <= 2500000]\n",
    "df = df[df['http.content_length'] <= 2000]\n",
    "\n",
    "#################################################################################\n",
    "# Convert tcp.options to length\n",
    "bool_col = ['tcp.connection.fin',\n",
    "            'tcp.connection.rst',\n",
    "            'tcp.connection.syn',\n",
    "            'tcp.connection.synack',\n",
    "            'tcp.flags.ack']\n",
    "df[bool_col] = df[bool_col].astype(int)\n",
    "\n",
    "#################################################################################\n",
    "# Convert tcp.options to length\n",
    "df['tcp.options'] = df['tcp.options'].apply(lambda x: len(x) if isinstance(x, str) else 0)\n",
    "\n",
    "#################################################################################\n",
    "# Convert frame.time to Datetime and create  1s Bins  \n",
    "df['frame.time'] = df['frame.time'].apply(lambda t: t[6:21])\n",
    "df['frame.time'] = pd.to_datetime(df['frame.time'], format='%H:%M:%S.%f')\n",
    "df['frame.time'] = df['frame.time'].dt.round('S')\n",
    "\n",
    "#################################################################################\n",
    "# Change Attack_types to Integers\n",
    "type_mapping = {\n",
    "    'Normal': 12,  # Assuming 12 is the label for Normal\n",
    "    'Backdoor': 0,\n",
    "    'DDoS_HTTP': 1,\n",
    "    'DDoS_ICMP': 2,\n",
    "    'DDoS_TCP': 3,\n",
    "    'OS_Fingerprinting': 4,\n",
    "    'Password': 5,\n",
    "    'Port_Scanning': 6,\n",
    "    'Ransomware': 7,\n",
    "    'SQL_injection': 8,\n",
    "    'Uploading': 9,\n",
    "    'Vulnerability_scanner': 10,\n",
    "    'XSS': 11}\n",
    "\n",
    "df['Attack_type'] = df['Attack_type'].replace(type_mapping)\n",
    "\n",
    "#################################################################################\n",
    "# Split Dataset into train and test\n",
    "X = df.drop(columns=['Attack_type', 'Attack_label'])\n",
    "y = pd.DataFrame(df['Attack_type'])\n",
    "y_label = df['Attack_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y,random_state=8)\n",
    "\n",
    "#################################################################################\n",
    "# Target Encoding\n",
    "col_to_target_encode = ['ip.src_host', \n",
    "                         'ip.dst_host', \n",
    "                         'tcp.dstport', \n",
    "                         'tcp.srcport']\n",
    "\n",
    "te = TargetEncoder(cols=col_to_target_encode)\n",
    "X_train[col_to_target_encode] = te.fit_transform(X_train[col_to_target_encode], y_train)\n",
    "X_test[col_to_target_encode] = te.transform(X_test[col_to_target_encode])\n",
    "#################################################################################\n",
    "# Normalisation \n",
    "bool_col = ['tcp.connection.fin',\n",
    "            'tcp.connection.rst',\n",
    "            'tcp.connection.syn',\n",
    "            'tcp.connection.synack',\n",
    "            'tcp.flags.ack']\n",
    "cols_ohe = ['arp.opcode',\n",
    "            'arp.hw.size',\n",
    "            'http.request.method',\n",
    "            'http.request.version',\n",
    "            'tcp.flags',\n",
    "            'tcp.options']\n",
    "\n",
    "cols_non_numeric = ['frame.time',\n",
    "                    'http.request.uri.query',\n",
    "                    'http.file_data']\n",
    "cols_to_not_normalize = bool_col + cols_non_numeric + cols_ohe\n",
    "cols_to_normalize = [col for col in X_train.columns if col not in cols_to_not_normalize]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[cols_to_normalize] = scaler.fit_transform(X_train[cols_to_normalize])\n",
    "X_test[cols_to_normalize] = scaler.transform(X_test[cols_to_normalize])\n",
    "\n",
    "#################################################################################\n",
    "# One Hot Encoding\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "X_train_encoded = ohe.fit_transform(X_train[cols_ohe])\n",
    "X_test_encoded = ohe.transform(X_test[cols_ohe])\n",
    "\n",
    "# Convert the encoded arrays to DataFrames with appropriate column names\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded, columns=ohe.get_feature_names_out(cols_ohe), index=X_train.index)\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=ohe.get_feature_names_out(cols_ohe), index=X_test.index)\n",
    "\n",
    "# Drop the original columns and concatenate the new encoded columns\n",
    "X_train = X_train.drop(columns=cols_ohe).join(X_train_encoded_df)\n",
    "X_test = X_test.drop(columns=cols_ohe).join(X_test_encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# Tokenisation\n",
    "cols_to_tokenize = ['http.request.uri.query', 'http.file_data']\n",
    "\n",
    "# Concatenate the columns to tokenize into a single string for each row\n",
    "def concatenate_columns(row):\n",
    "    col1 = 'http.request.uri.query'\n",
    "    col2 = 'http.file_data'\n",
    "    if row[col1] != '0' and row[col2] != '0':\n",
    "        return row[col1] + row[col2]\n",
    "    elif row[col1] == '0' and row[col2] == '0':\n",
    "        return '0'\n",
    "    else:\n",
    "        return row[col1] if row[col1] != '0' else row[col2]\n",
    "\n",
    "# Apply the function row-wise\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df = 0.01)\n",
    "\n",
    "df_concatenated_train = X_train[cols_to_tokenize].apply(concatenate_columns, axis=1)\n",
    "df_concatenated_test = X_test[cols_to_tokenize].apply(concatenate_columns, axis=1)\n",
    "\n",
    "normal_features_train = X_train.drop(columns=cols_to_tokenize)\n",
    "normal_features_test = X_test.drop(columns=cols_to_tokenize)\n",
    "\n",
    "tfidf_matrix_train = tfidf_vectorizer.fit_transform(df_concatenated_train)\n",
    "tfidf_matrix_test = tfidf_vectorizer.transform(df_concatenated_test)\n",
    "\n",
    "tfidf_df_train = pd.DataFrame(tfidf_matrix_train.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "tfidf_df_test = pd.DataFrame(tfidf_matrix_test.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Join the tfidf features back with the normal features\n",
    "X_train_combined = pd.concat([normal_features_train.reset_index(drop=True), tfidf_df_train.reset_index(drop=True)], axis=1)\n",
    "X_test_combined = pd.concat([normal_features_test.reset_index(drop=True), tfidf_df_test.reset_index(drop=True)], axis=1)\n",
    "\n",
    "\n",
    "X_train = X_train_combined\n",
    "X_test = X_test_combined\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the preprocessed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')\n",
    "y_train.to_pickle('y_train.pkl')\n",
    "y_test.to_pickle('y_test.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
